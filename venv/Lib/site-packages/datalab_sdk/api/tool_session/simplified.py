from os import access
from datalab_sdk.api.common.simplified import *
from datalab_sdk.api.tool_session.basic import * # want to make easy import for clients of SDK
from datalab_sdk.api.tool_session.exceptions import *
from datalab_sdk.api.tool_session.types.simplified_metadata import *
from datalab_sdk.api.platform.basic import (
    PlatformBasicClient,
    KeyValueField,
    KeyValueType,
    UploadRequestMetadata,
    Environment
)
from datalab_sdk.api.tool_inventory.basic import BasicToolInventoryClient
from datetime import datetime


# Simplified interface to the API, giving help around the most common use cases.
# Wrapper methods just simplify the interface, while added value methods integrate common actions.
class ToolSessionSimplifiedClient(CommonSimplifiedClient):
    # Identifiers
    SESSION_ID_KEY_VALUE_KEY = "session-id"
    REPORT_REGISTRATION_TYPE = "report"
    RECIPE_REGISTRATION_TYPE = "recipe"

    def __init__(self, environment: Environment = Environment.PROD):
        CommonSimplifiedClient.__init__(self)
        self.__api = ToolSessionBasicClient(environment=environment)
        self.__platform_api = PlatformBasicClient(environment=environment)
        self.__tool_inventory_api = BasicToolInventoryClient(environment=environment)

    # --- Added Value Method ---
    def get_expanded_session_context(self, token: str, url_query: str) -> ExpandedSessionContext:
        """Gets the tool session context, describing how the run the tool for that session,
        along with who is running the tool and version information/

        Arguments:
            token: str -- The auth token of the current auth session.
            url_query: str -- URL query section to parse the session id from.

        Returns:
            str -- String containing both the user name and their email address.

        Errors:
            AuthNotValid -- if token is invalid
            PlatformAccessError -- if getting the data failed.
        """
        session_id = self.__get_session_id_from_url_query(url_query)

        context = self.__api.get_context_by_session_id(token, session_id)
        tool_version_info = self.__tool_inventory_api.get_tool_version_by_id(
            token,
            context.tool_id,
            context.tool_version_id
        )
        user_data = self.__platform_api.get_user_data(token)

        # Combine our data into a single structure
        expanded_context = ExpandedSessionContext(
            session_id = session_id,
            name = context.name,
            tool_version = tool_version_info.version.version,
            configuration = tool_version_info.version.configuration,
            inputs = context.inputs,
            status = context.status,
            tool_viewer_access_groups = context.tool_viewer_access_groups,
            user = f"{user_data.user_name} ({user_data.email})"
        )

        return expanded_context

    # --- Added Value Method ---
    def save_session_outputs(
        self,
        token: str,
        session_id: str,
        session_name: str,
        outputs_timestamp: datetime,
        outputs: List[SnapshotOutputFile],
    ) -> str:
        """Saves the outputs of this session to DataLab, registers them to the session and ends the session.
        For use with tools which only create a single snapshot, such as ICE tools.

        Arguments:
            token: str -- The auth token of the current auth session.
            session_id: str -- Id of the session to get the data for.
            session_name: str -- Name of the session, given to the uploaded files.
            outputs_timestamp: str -- When the calculation was performed.
            outputs: List[SnapshotOutputFile] -- List of output files and metadata to upload and register against the session.

        Returns:
            str - URL of the results view in the Consumer UI, to redirect to.

        Errors:
            AuthNotValid -- if token is invalid
            PlatformAccessError -- if the upload or registration failed.
        """
        # Prepare to capture the data ids of uploaded outputs
        uploaded_outputs: List[SnapshotOutput] = []

        # Upload each file and record their data ids
        for output in outputs:
            uploaded_outputs.append(SnapshotOutput(
                name=output.name,
                type=output.type,
                source="Platform",
                source_id=self.__upload_output_file(token, output, session_id, session_name)
            ))

        # Finally, register the received repo ids to the session
        try:
            results_view_url = self.__api.register_snapshot(
                token,
                session_id,
                True,
                True,
                uploaded_outputs,
                outputs_timestamp.strftime("%d %B %Y %H:%M"),
            )
        except Exception as ex:
            logger.error(ex)
            raise SnapshotRegistrationFailed(session_id) from ex

        return results_view_url.results_view_url

    # --- Added Value Method ---
    def save_session_report_and_recipe(
        self,
        token: str,
        session_id: str,
        session_name: str,
        outputs_timestamp: datetime,
        report: bytes,
        version_id: str,
        tags: List[str] = [],
        recipe: str = None,
    ) -> str:
        """Saves the PDF report of this session to DataLab, along with an recipe, if applicable,
        then registers them to the session and ends the session.
        For use with tools which only create a single snapshot, such as ICE tools.

        Arguments:
            token: str -- The auth token of the current auth session.
            session_id: str -- Id of the session to get the data for.
            session_name: str -- Name of the session, given to the uploaded report.
            outputs_timestamp: str -- When the calculation was performed.
            report: bytes -- Report document, detailing the inputs and outputs, etc.
            version_id: str -- RBAC ACCESS who can access the uploaded files.
            tags: List[str] -- Tags to give the report and recipe, if any.
            recipe: str -- Recipe output from the calculation, if any, serialised to json.

        Returns:
            str - URL of the results view in the Consumer UI, to redirect to.

        Errors:
            AuthNotValid -- if token is invalid
            PlatformAccessError -- if the upload or registration failed.
        """
        report_file_name = f"{session_name if session_name else 'unnamed session'}.pdf"
        outputs = [
            SnapshotOutputFile(
                name="Report",
                type=self.REPORT_REGISTRATION_TYPE,
                data=report,
                file_name=report_file_name,
                tags=tags,
                key_value_fields=[],
                version_id=version_id,
            )
        ]

        if recipe:
            outputs.append(
                SnapshotOutputFile(
                    name="Recipe",
                    type=self.RECIPE_REGISTRATION_TYPE,
                    data=bytes(recipe, "utf-8"),
                    file_name="recipe.json",
                    tags=tags,
                    key_value_fields=[],
                    version_id=version_id,
                )
            )

        return self.save_session_outputs(
            token,
            session_id,
            session_name,
            outputs_timestamp,
            outputs,
        )

    # --- Helper Method ---
    def __get_session_id_from_url_query(self, url_query: str) -> str:
        """Gets the session id for this run of the tool from the query part
        of the URL.

        Arguments:
            url_query: str -- URL query section to parse the session id from.

        Returns:
            str -- Session identifier.
        """
        # We don't get the full URL, just the query part, e.g.
        # ?toolVersionId=810c7d23-d5b2-4e9b-bc71-ab6f3193ef54
        # &toolSessionId=618c86f0-eca9-498a-bab3-9fce7f444844,
        # so parse the string manually rather than using urllib
        if not "toolSessionId=" in url_query:
            raise UrlParsingFailed(url_query)
        try:
            session_id = url_query.split("toolSessionId=")[-1].split("&")[0]
            logger.debug(session_id)
        except Exception as ex:
            logger.error(ex)
            raise UrlParsingFailed(url_query) from ex

        return session_id

    # --- Helper Method ---
    def __upload_output_file(
        self,
        token: str,
        output_file: SnapshotOutputFile,
        session_id: str,
        session_name: str,
    ):
        """Uploads an ICE calculation output file, with appropriate metadata, to the immutable store in DataLab,
        and then locks the file.

        Arguments:
            token: str -- The auth token of the current auth session.
            data: bytes -- Data for the file.
            file_name: The -- Name of the file, should the user choose to download it.
            session_id: The -- Id of the session, to use within the file metadata.
            session_name: str -- Name of the session, given to the uploaded results.
        Returns:
            str - Repo id of the file in DataLab.

        Errors:
            PlatformAccessError -- if there is an error accessing DataLab
        """
        try:
            upload_response = self.__platform_api.upload_file(
                token,
                metadata=UploadRequestMetadata(
                    name=output_file.file_name,
                    description=session_name if session_name else "No description given.",
                    tags=output_file.tags,
                    key_value_fields=[
                        KeyValueField(self.SESSION_ID_KEY_VALUE_KEY, session_id, KeyValueType.STRING, []),
                    ] + output_file.key_value_fields,
                    version_id=output_file.version_id,
                    enable_mme_access=output_file.enable_mme_access,
                ),
                filename=output_file.file_name,
                data=output_file.data,
            )
        except Exception as ex:
            logger.error(f"Failed to upload output data \"{output_file.file_name}\" to DataLab.")
            logger.error(ex)
            raise ex

        logger.debug(f"Number of bytes uploaded: {len(output_file.data)}")

        if not upload_response.repo_id:
            no_repo_id_error_message = f"No repo id returned after upload of \"{output_file.file_name}\"."
            logger.error(no_repo_id_error_message)
            raise APIError(no_repo_id_error_message)

        # Now lock the file
        try:
            self.__platform_api.update_is_locked(token, upload_response.repo_id, is_locked=True)
        except Exception as ex:
            # If this fails it is not serious and the file will still be in DataLab. so we should continue
            logger.warning(f"Failed to lock output file repo \"{upload_response.repo_id}\".")
            logger.warning(ex)

        if not upload_response.data_id:
            no_data_id_error_message = f"No data id returned after upload of \"{output_file.file_name}\"."
            logger.error(no_data_id_error_message)
            raise APIError(no_data_id_error_message)

        return upload_response.data_id
